{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.copy()\n",
    "test_df = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('label', axis=1).values\n",
    "y = train_df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Redimensionar y normalizar\n",
    "X_train = X_train.reshape(28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Convertir etiquetas a one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "# Evaluar modelo\n",
    "test_loss, test_accuracy = network.evaluate(X_test, y_test)\n",
    "print(f\"Precisión en conjunto de pruebas: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "predict_and_generate_submission(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('label', axis=1).values\n",
    "y = train_df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Redimensionar y normalizar\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Convertir etiquetas a one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "model = models.Sequential([\n",
    "    # Capa de entrada con aumento de datos\n",
    "    layers.Input(input_shape),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    \n",
    "    # Bloque convolucional 1\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Bloque convolucional 2\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Bloque convolucional 3\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Capas completamente conectadas\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    # Capa de salida\n",
    "    layers.Dense(self.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.5, \n",
    "            patience=5, \n",
    "            min_lr=1e-6\n",
    "        )\n",
    "        \n",
    "        # Entrenamiento\n",
    "        \n",
    "history = self.model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stopping, lr_reducer],\n",
    "    verbose=1\n",
    ")\n",
    "        \n",
    "predictions = self.model.predict(X_test)\n",
    "            \n",
    "# Convertir predicciones a clases (números de dígitos)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Crear DataFrame para submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': range(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})\n",
    "\n",
    "# Guardar en CSV\n",
    "submission_df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Archivo de submission generado: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = network.model.predict(X_test)\n",
    "        \n",
    "# Convertir predicciones a clases (números de dígitos)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Crear DataFrame para submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': range(1, len(predicted_classes) + 1),\n",
    "    'Label': predicted_classes\n",
    "})\n",
    "\n",
    "# Guardar en CSV\n",
    "submission_df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Archivo de submission generado: {filename}\")\n",
    "return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
