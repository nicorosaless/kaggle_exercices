{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7   \n",
       "0      1       0       0       0       0       0       0       0       0  \\\n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779   \n",
       "0       0  ...         0         0         0         0         0         0  \\\n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.copy()\n",
    "test_df = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X = train_df.drop('label', axis=1).values\n",
    "y = train_df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Redimensionar y normalizar\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Convertir etiquetas a one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ImprovedNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128 * 3 * 3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ensure input is in the right shape [batch_size, channels, height, width]\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Training function with validation\n",
    "def train_model(model, train_loader, val_loader, epochs, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        val_acc = 100. * correct / total\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}/{epochs}')\n",
    "        print(f'Training Loss: {running_loss/len(train_loader):.3f} | Training Acc: {train_acc:.2f}%')\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.3f} | Validation Acc: {val_acc:.2f}%')\n",
    "        print('--------------------')\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n",
      "Training Loss: 0.234 | Training Acc: 92.58%\n",
      "Validation Loss: 0.052 | Validation Acc: 98.43%\n",
      "--------------------\n",
      "Epoch: 2/20\n",
      "Training Loss: 0.089 | Training Acc: 97.18%\n",
      "Validation Loss: 0.059 | Validation Acc: 98.33%\n",
      "--------------------\n",
      "Epoch: 3/20\n",
      "Training Loss: 0.063 | Training Acc: 98.02%\n",
      "Validation Loss: 0.044 | Validation Acc: 98.56%\n",
      "--------------------\n",
      "Epoch: 4/20\n",
      "Training Loss: 0.054 | Training Acc: 98.30%\n",
      "Validation Loss: 0.033 | Validation Acc: 98.90%\n",
      "--------------------\n",
      "Epoch: 5/20\n",
      "Training Loss: 0.047 | Training Acc: 98.57%\n",
      "Validation Loss: 0.046 | Validation Acc: 98.55%\n",
      "--------------------\n",
      "Epoch: 6/20\n",
      "Training Loss: 0.041 | Training Acc: 98.72%\n",
      "Validation Loss: 0.042 | Validation Acc: 98.62%\n",
      "--------------------\n",
      "Epoch: 7/20\n",
      "Training Loss: 0.036 | Training Acc: 98.83%\n",
      "Validation Loss: 0.036 | Validation Acc: 98.86%\n",
      "--------------------\n",
      "Epoch: 8/20\n",
      "Training Loss: 0.035 | Training Acc: 98.90%\n",
      "Validation Loss: 0.029 | Validation Acc: 99.17%\n",
      "--------------------\n",
      "Epoch: 9/20\n",
      "Training Loss: 0.033 | Training Acc: 99.01%\n",
      "Validation Loss: 0.032 | Validation Acc: 98.94%\n",
      "--------------------\n",
      "Epoch: 10/20\n",
      "Training Loss: 0.031 | Training Acc: 99.03%\n",
      "Validation Loss: 0.026 | Validation Acc: 99.15%\n",
      "--------------------\n",
      "Epoch: 11/20\n",
      "Training Loss: 0.027 | Training Acc: 99.20%\n",
      "Validation Loss: 0.029 | Validation Acc: 99.05%\n",
      "--------------------\n",
      "Epoch: 12/20\n",
      "Training Loss: 0.025 | Training Acc: 99.24%\n",
      "Validation Loss: 0.032 | Validation Acc: 99.01%\n",
      "--------------------\n",
      "Epoch: 13/20\n",
      "Training Loss: 0.025 | Training Acc: 99.21%\n",
      "Validation Loss: 0.027 | Validation Acc: 99.27%\n",
      "--------------------\n",
      "Epoch: 14/20\n",
      "Training Loss: 0.025 | Training Acc: 99.22%\n",
      "Validation Loss: 0.031 | Validation Acc: 99.13%\n",
      "--------------------\n",
      "Epoch: 15/20\n",
      "Training Loss: 0.012 | Training Acc: 99.60%\n",
      "Validation Loss: 0.026 | Validation Acc: 99.23%\n",
      "--------------------\n",
      "Epoch: 16/20\n",
      "Training Loss: 0.013 | Training Acc: 99.61%\n",
      "Validation Loss: 0.022 | Validation Acc: 99.38%\n",
      "--------------------\n",
      "Epoch: 17/20\n",
      "Training Loss: 0.011 | Training Acc: 99.63%\n",
      "Validation Loss: 0.025 | Validation Acc: 99.26%\n",
      "--------------------\n",
      "Epoch: 18/20\n",
      "Training Loss: 0.010 | Training Acc: 99.65%\n",
      "Validation Loss: 0.028 | Validation Acc: 99.33%\n",
      "--------------------\n",
      "Epoch: 19/20\n",
      "Training Loss: 0.010 | Training Acc: 99.68%\n",
      "Validation Loss: 0.024 | Validation Acc: 99.35%\n",
      "--------------------\n",
      "Epoch: 20/20\n",
      "Training Loss: 0.011 | Training Acc: 99.66%\n",
      "Validation Loss: 0.024 | Validation Acc: 99.33%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Preparación de datos\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "    torch.tensor(y_train.argmax(axis=1), dtype=torch.long)\n",
    ")\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "    torch.tensor(y_test.argmax(axis=1), dtype=torch.long)\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = ImprovedNeuralNetwork().to(device)\n",
    "model = train_model(model, train_loader, val_loader, epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions made: 28000\n",
      "\n",
      "Prediction distribution:\n",
      "Digit 0: 2778 images (9.9%)\n",
      "Digit 1: 3196 images (11.4%)\n",
      "Digit 2: 2818 images (10.1%)\n",
      "Digit 3: 2779 images (9.9%)\n",
      "Digit 4: 2759 images (9.9%)\n",
      "Digit 5: 2522 images (9.0%)\n",
      "Digit 6: 2745 images (9.8%)\n",
      "Digit 7: 2884 images (10.3%)\n",
      "Digit 8: 2749 images (9.8%)\n",
      "Digit 9: 2770 images (9.9%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test dataset\n",
    "test_samples = test_df.values.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "# Reorder dimensions to match PyTorch's expected format: [batch, channels, height, width]\n",
    "test_samples = np.transpose(test_samples, (0, 3, 1, 2))\n",
    "\n",
    "# Convert to tensor and move to device\n",
    "test_tensor = torch.tensor(test_samples, dtype=torch.float32).to(device)\n",
    "\n",
    "# Load the best model if you saved it during training\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.to(device)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "# Process in batches to avoid memory issues\n",
    "batch_size = 64\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_tensor), batch_size):\n",
    "        batch = test_tensor[i:i+batch_size]\n",
    "        outputs = model(batch)\n",
    "        pred_probab = nn.Softmax(dim=1)(outputs)\n",
    "        batch_preds = pred_probab.argmax(1).cpu().numpy()\n",
    "        predictions.extend(batch_preds)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': range(1, len(predictions) + 1),\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "# Save predictions\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Total predictions made: {len(predictions)}\")\n",
    "print(\"\\nPrediction distribution:\")\n",
    "for label in range(10):\n",
    "    count = (np.array(predictions) == label).sum()\n",
    "    percentage = (count / len(predictions)) * 100\n",
    "    print(f\"Digit {label}: {count} images ({percentage:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
